{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENSECO_04_RTM_Inversion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPfD4PDyiVKZ1tV2Mp5Z/ls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nunocesarsa/SENSECO_School_2021/blob/main/ColabNotebooks/SENSECO_04_RTM_Inversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIxdWMqjJRsm"
      },
      "source": [
        "#Setting up\n",
        "\n",
        "- Now we just skim through all those intermediate steps without much explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1BQ3f6XMYwt"
      },
      "source": [
        "## Setting up AutoSklearn\n",
        "\n",
        "- Restart runtime after running cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZIJo_fhHLwY"
      },
      "source": [
        "#source: https://colab.research.google.com/github/vopani/fortyone/blob/main/notebooks/automl/tabular/Auto-Sklearn.ipynb#scrollTo=yFSo4OV0FOZN\n",
        "\n",
        "!python3 -m pip install --upgrade pip\n",
        "!pip3 install scikit-learn==0.24.1\n",
        "!pip3 install pandas\n",
        "\n",
        "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip3 install\n",
        "!pip3 install auto-sklearn\n",
        "\n",
        "!pip install PipelineProfiler\n",
        "#NOTICE: you might be required to restart runtime before proceeding\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DiAnFvWZvns"
      },
      "source": [
        "## RESTART RUNTIME!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwYi3YEjMrLF"
      },
      "source": [
        "#quick test:\n",
        "from autosklearn.classification import AutoSklearnClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer(as_frame=True)['data']\n",
        "target = load_breast_cancer(as_frame=True)['target']\n",
        "\n",
        "sklearn_aml = AutoSklearnClassifier(time_left_for_this_task=30)\n",
        "sklearn_aml.fit(X=data, y=target)\n",
        "\n",
        "import PipelineProfiler\n",
        "prof_data = PipelineProfiler.import_autosklearn(sklearn_aml)\n",
        "PipelineProfiler.plot_pipeline_matrix(prof_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjxqlYz1OGqV"
      },
      "source": [
        "## Connecting to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq18lezUOJNu",
        "outputId": "d665246e-7a31-407b-aa9f-305d5f19c98b"
      },
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1t2pVbiMpvd"
      },
      "source": [
        "## Setting up PROSAIL et al"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqBm9TZONgpF"
      },
      "source": [
        "#Installing PROSAIL\n",
        "!pip install prosail\n",
        "\n",
        "#latin hypercube stuff\n",
        "!pip install lhsmdu\n",
        "\n",
        "#this package as a number of functions to deal with hyperspectral data\n",
        "!pip install pysptools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tgcgQb9NjE1"
      },
      "source": [
        "## Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40US8-GKOvik"
      },
      "source": [
        "#General purpose: \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from scipy import stats\n",
        "\n",
        "#for data storage\n",
        "import pickle \n",
        "import joblib\n",
        "\n",
        "#the beutiful R like data frame\n",
        "import pandas as pd\n",
        "\n",
        "#PROSPECT+SAIL Radiative transfer mode package\n",
        "import prosail\n",
        "\n",
        "#Sampling design package\n",
        "import lhsmdu\n",
        "\n",
        "#a few more stuff for random\n",
        "import random as rdm\n",
        "import math\n",
        "\n",
        "#package to for operations on spectral data\n",
        "import pysptools as sptool \n",
        "from pysptools import distance\n",
        "\n",
        "## AutoML\n",
        "import autosklearn\n",
        "from autosklearn.regression import AutoSklearnRegressor\n",
        "\n",
        "## Scikit learn metrics stuff\n",
        "import sklearn.metrics"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aObEthvqTBjH"
      },
      "source": [
        "## Loading *custom* PROSAIL Functions\n",
        "\n",
        "- These are the same functions we used earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kQVAlxBS_bl"
      },
      "source": [
        "def custom_prosail(cab,lai,sol_zen,inc_zen,raa):\n",
        "  \n",
        "  import prosail\n",
        "  #\"default\" parameters\n",
        "  cm = 0.005\n",
        "  cw = 0.005\n",
        "  n= 1.\n",
        "  car=10.\n",
        "  cbrown=0.01\n",
        "  typelidf=1 #this is the default option\n",
        "  lidfa = -1 #leaf angle distribution parameter a and b\n",
        "  lidfb=-0.15\n",
        "  hspot= 0.01 #hotspot parameters \n",
        "\n",
        "  #sun and viewing angle\n",
        "  #tts=30. #observation and solar position parameters\n",
        "  #tto=10. \n",
        "  #psi=0.\n",
        "\n",
        "  #for now i put them by hand but they should be an input of a custom function\n",
        "  tts=sol_zen #solar zenith angle\n",
        "  tto=inc_zen #sensor zenith angle\n",
        "  psi=raa\n",
        "\n",
        "  \n",
        "\n",
        "  rho_out = prosail.run_prosail(n,\n",
        "                                 cab,\n",
        "                                 car,\n",
        "                                 cbrown,\n",
        "                                 cw,\n",
        "                                 cm,\n",
        "                                 lai,\n",
        "                                 lidfa,\n",
        "                                 hspot,\n",
        "                                 tts,tto,psi,\n",
        "                                 typelidf, lidfb,\n",
        "                                 prospect_version=\"D\",\n",
        "                                 factor='SDR', \n",
        "                                 rsoil=.5, psoil=.5)\n",
        "  return(rho_out)\n",
        "\n",
        "\n",
        "#here you should change so it points to your file\n",
        "filepath=\"/content/drive/MyDrive/SENSECO_S2Data/S2_Responses_S2A.csv\"\n",
        "\n",
        "def Prosail2S2(path2csv,spectra_input):\n",
        "\n",
        "  #pointing needed packages\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  #upload a S2_Response.csv from https://earth.esa.int/web/sentinel/user-guides/sentinel-2-msi/document-library/-/asset_publisher/Wk0TKajiISaR/content/sentinel-2a-spectral-responses\n",
        "\n",
        "  s2_table = pd.read_csv(path2csv,sep=\";\",decimal=\",\") #check if this is proper, regarding the sep and dec\n",
        "  #chekc which row you are actually extracting\n",
        "\n",
        "  s2_table_sel = s2_table[s2_table['SR_WL'].between(400,2500)] #selects all values between 400 and 2500\n",
        "  spectra_input_df = pd.DataFrame(data=spectra_input,columns=[\"rho\"],index=s2_table_sel.index) #transforms the input array into a pandas df with the column name rho and row.index = to the original input table\n",
        "\n",
        "  rho_s2 = s2_table_sel.multiply(spectra_input_df['rho'],axis=\"index\") #calculates the numerator\n",
        "  w_band_sum = s2_table_sel.sum(axis=0,skipna = True) #calculates the denominator\n",
        "\n",
        "  output = (rho_s2.sum(axis=0)/w_band_sum).rename_axis(\"ID\").values #runs the weighted mean and converts the output to a numpy array\n",
        "\n",
        "  return output[1:] #removes the first value because it represents the wavelength column\n",
        "\n",
        "\n",
        "def Gen_spectra_data(input_param_table,doPlot=False,bandlist=[0,1,2,3,4,5,6,7,8,9,10,11,12]):\n",
        "  k = 1\n",
        "  #pd_train_traits=traits\n",
        "  #print(range(len(traits)))\n",
        "  import matplotlib.pyplot as plt\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  \n",
        "  for i in range(len(input_param_table)):\n",
        "\n",
        "    #edit this section accordingly\n",
        "    filepath = \"/content/drive/MyDrive/SENSECO_S2Data/S2_Responses_S2A.csv\"\n",
        "\n",
        "    #vegetation parametrs\n",
        "    cab_t = input_param_table[\"cab\"][i]\n",
        "    lai_t = input_param_table[\"lai\"][i]\n",
        "\n",
        "    #observation parameters\n",
        "    sol_zen_t = input_param_table[\"sol_zen\"][i]\n",
        "    inc_zen_t = input_param_table[\"inc_zen\"][i]\n",
        "    raa_t     = input_param_table[\"raa\"][i]\n",
        "\n",
        "    if k == 1:\n",
        "\n",
        "      tr_rho_s = custom_prosail(cab_t,lai_t,sol_zen_t,inc_zen_t,raa_t)\n",
        "      tr_rho_s = Prosail2S2(filepath,tr_rho_s)[bandlist,]\n",
        "\n",
        "      if doPlot == True:\n",
        "        x = bandlist\n",
        "        plt.plot ( x, tr_rho_s)\n",
        "        #plt.legend(loc='best')\n",
        "      \n",
        "    if k > 1:\n",
        "      tr_rho_t = custom_prosail(cab_t,lai_t,sol_zen_t,inc_zen_t,raa_t)\n",
        "      tr_rho_t = Prosail2S2(filepath,tr_rho_t)[bandlist,]\n",
        "      tr_rho_s = np.vstack((tr_rho_s,tr_rho_t))\n",
        "\n",
        "      if doPlot == True:\n",
        "        plt.plot ( x, tr_rho_t)\n",
        "\n",
        "    k = k+1\n",
        "\n",
        "  rho_samples=tr_rho_s\n",
        "  return rho_samples\n",
        "\n",
        "def combined_noise(ref,sigma):\n",
        "\n",
        "  #ref is an input vector and sigma is the standar deviation of the noise - there is a possibilityu of values going over over 1 or lower than 0 But those values are corrected in the end. \n",
        "  \n",
        "  mp_noise = ref*(1 + stats.truncnorm.rvs(0-sigma*4,0+sigma*4,loc=0,scale=sigma*2,size=ref.shape[0]))\n",
        "  ad_noise = 0+stats.truncnorm.rvs(0-sigma*2,0+sigma*2,loc=0,scale=sigma,size=ref.shape[0])\n",
        "  out_ref = mp_noise+ ad_noise\n",
        "\n",
        "  #making everything that goes under, be 0 or 1\n",
        "  out_ref[out_ref>1]=1\n",
        "  out_ref[out_ref<0]=0\n",
        "\n",
        "  return out_ref"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA0tixSHP9Qm"
      },
      "source": [
        "### Quick test:\n",
        "\n",
        "- just to make sure everything is ready to go"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX3g2UNtPxuv"
      },
      "source": [
        "#generating LHS random matrix\n",
        "LHS_train = lhsmdu.createRandomStandardUniformMatrix(5,10)\n",
        "\n",
        "#then we convert this into a Pandas table and rename it\n",
        "pd_param_input = pd.DataFrame.transpose(pd.DataFrame(LHS_train))\n",
        "pd_param_input.columns = [\"cab\",\"lai\",\"sol_zen\",\"inc_zen\",\"raa\"]\n",
        "\n",
        "#vegetation parameters\n",
        "pd_param_input[\"cab\"]    =pd_param_input[\"cab\"]*80+20\n",
        "pd_param_input[\"lai\"]    =pd_param_input[\"lai\"]*6+1\n",
        "\n",
        "#observation parameters - for now very small and basic\n",
        "pd_param_input[\"sol_zen\"]=pd_param_input[\"sol_zen\"]*31+29\n",
        "pd_param_input[\"inc_zen\"]=pd_param_input[\"inc_zen\"]*31+29\n",
        "pd_param_input[\"raa\"]    =pd_param_input[\"raa\"]*31+29\n",
        "\n",
        "#test the function\n",
        "test_spectra = Gen_spectra_data(pd_param_input,doPlot=True,bandlist=[1,2,3,4,5,6,7,11,12])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPX7tHHG8Mzu"
      },
      "source": [
        "### Adding noise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ejaYMWo7SjL"
      },
      "source": [
        "#adding noise:\n",
        "test_spectra_noise = np.apply_along_axis(combined_noise,1,test_spectra,sigma=0.05)\n",
        "test_spectra_noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diHHa65dXtjx"
      },
      "source": [
        "# Generating data\n",
        "\n",
        "- Now, we want to generate a N number of samples that will be used for training the actual models for RTM inversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-BfKCy1XylZ"
      },
      "source": [
        "n_samples = 1000\n",
        "\n",
        "#generating LHS random matrix\n",
        "LHS_train = lhsmdu.createRandomStandardUniformMatrix(5,n_samples)\n",
        "\n",
        "#then we convert this into a Pandas table and rename it\n",
        "pd_param_input = pd.DataFrame.transpose(pd.DataFrame(LHS_train))\n",
        "pd_param_input.columns = [\"cab\",\"lai\",\"sol_zen\",\"inc_zen\",\"raa\"]\n",
        "\n",
        "#vegetation parameters\n",
        "pd_param_input[\"cab\"]    =pd_param_input[\"cab\"]*60+20\n",
        "pd_param_input[\"lai\"]    =pd_param_input[\"lai\"]*6+1\n",
        "\n",
        "#observation parameters - Based on the data we will use later\n",
        "pd_param_input[\"sol_zen\"]=pd_param_input[\"sol_zen\"]*45+15 # the average is aroudn 39 but the maximum is just below 60 and the minimum is 18.\n",
        "pd_param_input[\"inc_zen\"]=pd_param_input[\"inc_zen\"]*2+3 # the average is around 4 - so now the data varies between 3 and 5\n",
        "pd_param_input[\"raa\"]    =pd_param_input[\"raa\"]*50+80 # the avreage is aroudn 100 but the maximum is 128 and the min 84. \n",
        "\n",
        "#generating 1000 samples\n",
        "np_spectra = Gen_spectra_data(pd_param_input,bandlist=[1,2,3,4,5,6,7,11,12])\n",
        "\n",
        "#adding noise - comment this line if you want to try a pure spectra inversion\n",
        "np_spectra = np.apply_along_axis(combined_noise,1,np_spectra,sigma=0.05)\n",
        "\n",
        "#creating a pandas table because why not \n",
        "pd_spectra = pd.DataFrame(data=np_spectra,columns=[\"B02\",\"B03\",\"B04\",\n",
        "                                                   \"B05\",\"B06\",\"B07\",\n",
        "                                                   \"B8A\",\"B11\",\"B12\"])\n",
        "\n",
        "#combines all the data into one single csv\n",
        "pd_alldata = pd.concat([pd_param_input, pd_spectra], axis=1)\n",
        "\n",
        "#first step is always dividing the dataset between validation and training:\n",
        "pd_train = pd_alldata.sample(frac=0.8,random_state=200)\n",
        "pd_test  = pd_alldata.drop(pd_train.index)\n",
        " "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqDCFl5oF3-j"
      },
      "source": [
        "pd_alldata.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvrwzPE6dMa9"
      },
      "source": [
        "#AutoSklearn\n",
        "\n",
        "FYI: https://automl.github.io/auto-sklearn/master/_modules/autosklearn/estimators.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEmy66l3gadl"
      },
      "source": [
        "## Data set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTbPkA3kY6VZ"
      },
      "source": [
        "#Autosklearn expects input data as: x, y in separate datasets\n",
        "pd_train_y = pd_train[[\"cab\",\"lai\"]]\n",
        "pd_train_x = pd_train[[\"sol_zen\",\"inc_zen\",\"raa\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B8A\",\"B11\",\"B12\"]]\n",
        "\n",
        "pd_test_y = pd_test[[\"cab\",\"lai\"]]\n",
        "pd_test_x = pd_test[[\"sol_zen\",\"inc_zen\",\"raa\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B8A\",\"B11\",\"B12\"]]\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_9a5QXHgZ77"
      },
      "source": [
        "# First model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qieRpzvMgkxE"
      },
      "source": [
        "#Default settings (except for time)\n",
        "AutoRTM_0030 = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task=30)\n",
        "AutoRTM_0030.fit(pd_train_x,pd_train_y,pd_test_x,pd_test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vml2DxZfjNhG"
      },
      "source": [
        "## Checking error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv-G7d35ixxv"
      },
      "source": [
        "predictions_0030 = AutoRTM_0030.predict(pd_test_x)\n",
        "print(\"Cab MAE:\", sklearn.metrics.mean_absolute_error(pd_test_y[\"cab\"], predictions_0030[:,0]))\n",
        "print(\"LAI MAE:\", sklearn.metrics.mean_absolute_error(pd_test_y[\"lai\"], predictions_0030[:,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUHRpEizjQ48"
      },
      "source": [
        "## Exploring pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bx8GBYSiBI2"
      },
      "source": [
        "AutoRTM_0030_pipeline = PipelineProfiler.import_autosklearn(AutoRTM_0030)\n",
        "PipelineProfiler.plot_pipeline_matrix(AutoRTM_0030_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MRYWJIDkh7l"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqLojgcGkkuz"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2)\n",
        "ax1.plot(predictions_0030[:,0],pd_test_y[\"cab\"],\"o\")\n",
        "ax2.plot(predictions_0030[:,1],pd_test_y[\"lai\"],\"o\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtI5BMeIjmq1"
      },
      "source": [
        "# Second model\n",
        "\n",
        "-  here we increase the time for 5 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNHDolfyjlxO"
      },
      "source": [
        "#Default settings (except for time)\n",
        "AutoRTM_0300 = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task=300)\n",
        "AutoRTM_0300.fit(pd_train_x,pd_train_y,pd_test_x,pd_test_y)\n",
        "\n",
        "predictions_0300 = AutoRTM_0300.predict(pd_test_x)\n",
        "print(\"Cab MAE:\", sklearn.metrics.mean_absolute_error(pd_test_y[\"cab\"], predictions_0300[:,0]))\n",
        "print(\"LAI MAE:\", sklearn.metrics.mean_absolute_error(pd_test_y[\"lai\"], predictions_0300[:,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_fLIqGiBmNG"
      },
      "source": [
        "AutoRTM_0300_pipeline = PipelineProfiler.import_autosklearn(AutoRTM_0300)\n",
        "PipelineProfiler.plot_pipeline_matrix(AutoRTM_0300_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx_RsKO0qE3o"
      },
      "source": [
        "Gaussian processes @ autosklearn github:\n",
        "\n",
        " https://github.com/automl/auto-sklearn/blob/master/autosklearn/pipeline/components/regression/gaussian_process.py\n",
        "\n",
        "The model optimizes the lenghscale bounds: https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ML3KPEEmQCC"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2)\n",
        "ax1.plot(predictions_0300[:,0],pd_test_y[\"cab\"],\"o\")\n",
        "ax2.plot(predictions_0300[:,1],pd_test_y[\"lai\"],\"o\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSvYc_Ato7mI"
      },
      "source": [
        "### Accuracy over time\n",
        "\n",
        "Using the suggestion from the manual: https://automl.github.io/auto-sklearn/master/examples/40_advanced/example_pandas_train_test.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE58qyZVqt2h"
      },
      "source": [
        "from smac.tae import StatusType\n",
        "import time\n",
        "\n",
        "def get_runhistory_models_performance(automl):\n",
        "    metric = AutoRTM_0300.automl_._metric\n",
        "    data = automl.automl_.runhistory_.data\n",
        "    performance_list = []\n",
        "    for run_key, run_value in data.items():\n",
        "        if run_value.status != StatusType.SUCCESS:\n",
        "            # Ignore crashed runs\n",
        "            continue\n",
        "        # Alternatively, it is possible to also obtain the start time with ``run_value.starttime``\n",
        "        endtime = pd.Timestamp(time.strftime('%Y-%m-%d %H:%M:%S',\n",
        "                                             time.localtime(run_value.endtime)))\n",
        "        val_score = metric._optimum - (metric._sign * run_value.cost)\n",
        "        test_score = metric._optimum - (metric._sign * run_value.additional_info['test_loss'])\n",
        "        train_score = metric._optimum - (metric._sign * run_value.additional_info['train_loss'])\n",
        "        performance_list.append({\n",
        "            'Timestamp': endtime,\n",
        "            'single_best_optimization_score': val_score,\n",
        "            'single_best_test_score': test_score,\n",
        "            'single_best_train_score': train_score,\n",
        "        })\n",
        "    return pd.DataFrame(performance_list)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxaqkYw0pDbO"
      },
      "source": [
        "ensemble_performance_frame = pd.DataFrame(AutoRTM_0300.automl_.ensemble_performance_history)\n",
        "best_values = pd.Series({'ensemble_optimization_score': -np.inf,\n",
        "                         'ensemble_test_score': -np.inf})\n",
        "\n",
        "for idx in ensemble_performance_frame.index:\n",
        "    if (\n",
        "        ensemble_performance_frame.loc[idx, 'ensemble_optimization_score']\n",
        "        > best_values['ensemble_optimization_score']\n",
        "    ):\n",
        "        best_values = ensemble_performance_frame.loc[idx]\n",
        "    ensemble_performance_frame.loc[idx] = best_values\n",
        "\n",
        "individual_performance_frame = get_runhistory_models_performance(AutoRTM_0300)\n",
        "best_values = pd.Series({'single_best_optimization_score': -np.inf,\n",
        "                         'single_best_test_score': -np.inf,\n",
        "                         'single_best_train_score': -np.inf})\n",
        "for idx in individual_performance_frame.index:\n",
        "    if (\n",
        "        individual_performance_frame.loc[idx, 'single_best_optimization_score']\n",
        "        > best_values['single_best_optimization_score']\n",
        "    ):\n",
        "        best_values = individual_performance_frame.loc[idx]\n",
        "    individual_performance_frame.loc[idx] = best_values\n",
        "\n",
        "pd.merge(\n",
        "    ensemble_performance_frame,\n",
        "    individual_performance_frame,\n",
        "    \n",
        "    on=\"Timestamp\", how='outer'\n",
        ").sort_values('Timestamp').fillna(method='ffill').plot(\n",
        "    x='Timestamp',\n",
        "    kind='line',\n",
        "    legend=True,\n",
        "    title='Auto-sklearn accuracy over time',\n",
        "    grid=True,\n",
        "    figsize=(10,10),\n",
        ")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSnWvEIa9BDq"
      },
      "source": [
        "#!!!Problem!!!\n",
        "\n",
        "**Gaussian process for RTM inversion can be prone to overfitting**. Often it works well with \"pure\" inversion but can easily produce \"wacky\" results when using real data.\n",
        "\n",
        "This can be avoided by adding some \"noise\" to the data and by adding some \"leeway\" to the alpha parameter.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html#sklearn.gaussian_process.GaussianProcessRegressor\n",
        "\n",
        "Alpha: \"*Value added to the diagonal of the kernel matrix during fitting. This can prevent a potential numerical issue during fitting, by ensuring that the calculated values form a positive definite matrix. It can also be interpreted as the variance of additional Gaussian measurement noise on the training observations.*\"\n",
        "\n",
        "\n",
        "To solve that, we need to dwelve a bit deeper into autosklearn and create a new model classs that will become available for use. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2apZwYn3eYE"
      },
      "source": [
        "##Advanced - Adding new estimators:\n",
        "\n",
        "Changing AutoSklearn so we can configure a bit the hyperparameter space\n",
        "\n",
        "Adapting from:\n",
        "https://automl.github.io/auto-sklearn/master/examples/80_extending/example_restrict_number_of_hyperparameters.html#sphx-glr-examples-80-extending-example-restrict-number-of-hyperparameters-py\n",
        "\n",
        "List of Default regression models: https://github.com/automl/auto-sklearn/tree/master/autosklearn/pipeline/components/regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sHVxhyQ3vo2"
      },
      "source": [
        "## New GP class: \n",
        "\n",
        "- original class: https://github.com/automl/auto-sklearn/blob/master/autosklearn/pipeline/components/regression/gaussian_process.py\n",
        "\n",
        "- Useful resource: https://github.com/automl/auto-sklearn/blob/master/examples/80_extending/example_extending_regression.py\n",
        "\n",
        "- objective is to force a minimum 0.05 alpha parameter so we dont risk overfitting the artificial data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bGP0Dlq3lOt"
      },
      "source": [
        "from ConfigSpace.configuration_space import ConfigurationSpace\n",
        "from ConfigSpace.hyperparameters import UniformFloatHyperparameter\n",
        "\n",
        "from autosklearn.pipeline.components.base import AutoSklearnRegressionAlgorithm\n",
        "from autosklearn.pipeline.constants import DENSE, UNSIGNED_DATA, PREDICTIONS\n",
        "\n",
        "class GaussianProcess2(AutoSklearnRegressionAlgorithm):\n",
        "    def __init__(self, alpha, thetaL, thetaU, random_state=None):\n",
        "        self.alpha = alpha\n",
        "        self.thetaL = thetaL\n",
        "        self.thetaU = thetaU\n",
        "        # We ignore it\n",
        "        self.random_state = random_state\n",
        "        self.estimator = None\n",
        "        self.scaler = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        import sklearn.gaussian_process\n",
        "\n",
        "        self.alpha = float(self.alpha)\n",
        "        self.thetaL = float(self.thetaL)\n",
        "        self.thetaU = float(self.thetaU)\n",
        "\n",
        "        n_features = X.shape[1] \n",
        "        kernel = sklearn.gaussian_process.kernels.RBF( #here we could change the kernel parameters - notice also that deeper changes are needed to allow for kernel search\n",
        "            length_scale=[1.0]*n_features,\n",
        "            length_scale_bounds=[(self.thetaL, self.thetaU)]*n_features)\n",
        "\n",
        "        # Instanciate a Gaussian Process model\n",
        "        self.estimator = sklearn.gaussian_process.GaussianProcessRegressor(\n",
        "            kernel=kernel,\n",
        "            n_restarts_optimizer=10,\n",
        "            optimizer='fmin_l_bfgs_b',\n",
        "            alpha=self.alpha,\n",
        "            copy_X_train=True,\n",
        "            random_state=self.random_state,\n",
        "            normalize_y=True)\n",
        "\n",
        "        self.estimator.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.estimator is None:\n",
        "            raise NotImplementedError\n",
        "        return self.estimator.predict(X)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_properties(dataset_properties=None):\n",
        "        return {'shortname': 'GP',\n",
        "                'name': 'Gaussian Process',\n",
        "                'handles_regression': True,\n",
        "                'handles_classification': False,\n",
        "                'handles_multiclass': False,\n",
        "                'handles_multilabel': False,\n",
        "                'handles_multioutput': True,\n",
        "                'is_deterministic': True,\n",
        "                'input': (DENSE, UNSIGNED_DATA),\n",
        "                'output': (PREDICTIONS,)}\n",
        "\n",
        "    @staticmethod\n",
        "    def get_hyperparameter_search_space(dataset_properties=None):\n",
        "        alpha = UniformFloatHyperparameter(\n",
        "            name=\"alpha\", lower=0.05, upper=1.0, default_value=0.05, log=True) #NOTICE HERE - i am forcing a lower bound of 0.05 for the alpha parameter\n",
        "        thetaL = UniformFloatHyperparameter(\n",
        "            name=\"thetaL\", lower=1e-10, upper=1e-3, default_value=1e-6, log=True)\n",
        "        thetaU = UniformFloatHyperparameter(\n",
        "            name=\"thetaU\", lower=1.0, upper=100000, default_value=100000.0, log=True)\n",
        "\n",
        "        cs = ConfigurationSpace()\n",
        "        cs.add_hyperparameters([alpha, thetaL, thetaU])\n",
        "        return cs"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSlfCnQk4Yzl"
      },
      "source": [
        "#Pushing the changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ7xdbo90n4N"
      },
      "source": [
        "autosklearn.pipeline.components.regression.add_regressor(GaussianProcess2)\n",
        "cs = GaussianProcess2.get_hyperparameter_search_space()\n",
        "print(cs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQtyOwR75mpV"
      },
      "source": [
        "## Restricted model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Pn1ZocyhpL"
      },
      "source": [
        "\n",
        "#we can FORCE autosklearn to try ONLY specific models. And we will use this to compare RF against GP\n",
        "AutoRTM_Restricted = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task=120,\n",
        "                                                                 include_estimators=[\"GaussianProcess2\", \"gaussian_process\",\"random_forest\" ])\n",
        "AutoRTM_Restricted.fit(pd_train_x,pd_train_y,pd_test_x,pd_test_y)\n",
        "\n",
        "predictions_rest = AutoRTM_Restricted.predict(pd_test_x)\n",
        "print(\"Cab MAE:\", sklearn.metrics.mean_absolute_error(pd_test_y[\"cab\"], predictions_rest[:,0]))\n",
        "print(\"LAI MAE:\", sklearn.metrics.mean_absolute_error(pd_test_y[\"lai\"], predictions_rest[:,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p_pa-ybE_2f"
      },
      "source": [
        "AutoRTM_Restricted_pipeline = PipelineProfiler.import_autosklearn(AutoRTM_Restricted)\n",
        "PipelineProfiler.plot_pipeline_matrix(AutoRTM_Restricted_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8qqYazr78eW"
      },
      "source": [
        "## Plotting example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CscBuKwX8CU9"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2)\n",
        "ax1.plot(predictions_rest[:,0],pd_test_y[\"cab\"],\"o\")\n",
        "ax2.plot(predictions_rest[:,1],pd_test_y[\"lai\"],\"o\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0K8G6AAGApK"
      },
      "source": [
        "#Saving models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7Ehv9A3GvUB",
        "outputId": "ea10a279-1dd7-4718-eb70-2cda7a0a1cd2"
      },
      "source": [
        "import joblib\n",
        "joblib.dump(AutoRTM_0030, '/content/drive/MyDrive/SENSECO/Models/AutoRTM_0030.pkl')\n",
        "joblib.dump(AutoRTM_0300, '/content/drive/MyDrive/SENSECO/Models/AutoRTM_0300.pkl')\n",
        "joblib.dump(AutoRTM_Restricted, '/content/drive/MyDrive/SENSECO/Models/AutoRTM_Restricted.pkl')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/SENSECO/Models/AutoRTM_Restricted.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlCaplstIanb"
      },
      "source": [
        "#Loading example and confirming it loaded the right model\n",
        "\n",
        "loaded_mdl =  joblib.load('/content/drive/MyDrive/SENSECO/Models/AutoRTM_Restricted.pkl')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7b8iL_-Iujb"
      },
      "source": [
        "PipelineProfiler.plot_pipeline_matrix(AutoRTM_Restricted_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-7LGxabI9Sy"
      },
      "source": [
        "loaded_mdl_pipeline = PipelineProfiler.import_autosklearn(loaded_mdl)\n",
        "PipelineProfiler.plot_pipeline_matrix(loaded_mdl_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}