{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENSECO_07_NEON_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNNDQG4WNxldYOzNvZynZT4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nunocesarsa/SENSECO_School_2021/blob/main/ColabNotebooks/SENSECO_07_NEON_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP6DURv8mKYp"
      },
      "source": [
        "#Notice\n",
        "\n",
        "This part of the script has many \"data engineering\" steps that are convoluted to explain. \n",
        "\n",
        "The steps consists of:\n",
        "\n",
        "- first loading the field LAI data and then generating a continuos time series using linear interpolation.\n",
        "\n",
        "- extracting the value of this new interpolated dataset to the same dates of remote sensing observations\n",
        "\n",
        "- extracting the values from the raster datasets and then comparing them\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34zdR3Fgzi6G"
      },
      "source": [
        "## GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxRGK07tzpYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "877697b8-39bb-4383-9b33-faef0ff97f84"
      },
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPF3Wu1hp9iP"
      },
      "source": [
        "#Installing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3_48HE_p-sv"
      },
      "source": [
        "!pip install geopandas\n",
        "#!pip install pyrsgis\n",
        "!pip install earthpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEWM7ARIOJeW"
      },
      "source": [
        "#Loading packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0xr5rhcOLpn"
      },
      "source": [
        "#General purpose: \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "#the beutiful R like data frame\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "#raster stuff\n",
        "#from pyrsgis import raster\n",
        "import earthpy.plot as ep\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyLiKH1_N3__"
      },
      "source": [
        "#Step 1: NEON data\n",
        "\n",
        "- this data was collected from NEON as an example for this workshop\n",
        "- it provides geolocated samples of Leaf Area Index which we will use to compare against our results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke3vM-QfNSXM"
      },
      "source": [
        "neon_data = pd.read_csv('/content/drive/MyDrive/SENSECO_S2Data/CLBJ_Final_csv12.csv',sep=\";\",decimal=\".\")\n",
        "\n",
        "print(neon_data.shape)\n",
        "\n",
        "## and then we make a selection of the repeated observations\n",
        "neon_data = neon_data[neon_data['plotID'].isin([\"CLBJ_001\",\"CLBJ_002\",\"CLBJ_003\"])]\n",
        "\n",
        "print(neon_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdmlVThgPmk2"
      },
      "source": [
        "## Setting up NEON data\n",
        "\n",
        "Some of the steps are just to simplify the use of the dataset later on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N39Kgws8QFSv"
      },
      "source": [
        "#creating a year and month column\n",
        "neon_data[\"Year\"]  = neon_data.startDate.str[0:4]\n",
        "neon_data[\"Month\"] = neon_data.startDate.str[5:7]\n",
        "\n",
        "#there is information on the dataset about when the image was acquired but we wil ignore it this time and just use day 15th of each month\n",
        "neon_data[\"Day\"] = str(15)\n",
        "\n",
        "#creating a compact column\n",
        "neon_data[\"YMD\"] =  neon_data[\"Year\"] +  \"-\" + neon_data[\"Month\"] + \"-\" +  neon_data[\"Day\"]\n",
        "\n",
        "#creating a datetime type column\n",
        "neon_data[\"datetime\"] = pd.to_datetime(neon_data.YMD)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nlks1JhtXmvu"
      },
      "source": [
        "### Exploring\n",
        "\n",
        "- maybe some of you have nice ideas how to plot this nicely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPfk4bcbaKes"
      },
      "source": [
        "neon_sel = neon_data[[\"datetime\",\"Final_LAI\",\"plotID\"]]\n",
        "neon_sel.plot(x='datetime',style='k.',figsize=(15,10))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hh7gNP-cCdE"
      },
      "source": [
        "## Interpolating missing data\n",
        "\n",
        "Following this example: https://towardsdatascience.com/how-to-interpolate-time-series-data-in-apache-spark-and-python-pandas-part-1-pandas-cff54d76a2ea"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu7ylvRedr3z"
      },
      "source": [
        "#selecting only the columns im interested on\n",
        "neon_sel = neon_data[[\"datetime\",\"plotID\",\"Final_LAIe\",\"Final_LAI\",]]\n",
        "\n",
        "neon_sel.index = neon_sel['datetime']\n",
        "del neon_sel['datetime']\n",
        "\n",
        "#this could also be done using the original dataset but for clarity\n",
        "neon_sel_001 = neon_sel[neon_sel[\"plotID\"]==\"CLBJ_001\"]\n",
        "neon_sel_002 = neon_sel[neon_sel[\"plotID\"]==\"CLBJ_002\"]\n",
        "neon_sel_003 = neon_sel[neon_sel[\"plotID\"]==\"CLBJ_003\"]\n",
        "\n",
        "#peaking to an incomplete series\n",
        "#neon_sel_001.plot(x='datetime',style='k.',figsize=(15,10),colormap='GnBu'\n",
        "neon_sel_001.plot(style='.',figsize=(15,5), title = \"Original CLBJ 001\")\n",
        "\n",
        "neon_sel_001 = neon_sel_001.resample('D').mean()\n",
        "neon_sel_001[\"Final_LAIe\"] = neon_sel_001[\"Final_LAIe\"].interpolate()\n",
        "neon_sel_001[\"Final_LAI\"]  = neon_sel_001[\"Final_LAI\"].interpolate()\n",
        "neon_sel_001.plot(style='.',figsize=(15,5), title = \"Interpolated CLBJ 001\")\n",
        "\n",
        "neon_sel_002 = neon_sel_001.resample('D').mean()\n",
        "neon_sel_002[\"Final_LAIe\"] = neon_sel_002[\"Final_LAIe\"].interpolate()\n",
        "neon_sel_002[\"Final_LAI\"]  = neon_sel_002[\"Final_LAI\"].interpolate()\n",
        "\n",
        "neon_sel_003 = neon_sel_001.resample('D').mean()\n",
        "neon_sel_003[\"Final_LAIe\"] = neon_sel_002[\"Final_LAIe\"].interpolate()\n",
        "neon_sel_003[\"Final_LAI\"]  = neon_sel_002[\"Final_LAI\"].interpolate()\n",
        "\n",
        "\n",
        "#and now we can save the interpolated data\n",
        "neon_sel_001.to_csv(\"/content/drive/MyDrive/SENSECO/Outputs/Tables/CLBJ_001_csv.csv\")\n",
        "neon_sel_001.to_csv(\"/content/drive/MyDrive/SENSECO/Outputs/Tables/CLBJ_001_csv_Nuno.csv\",sep=\";\",decimal=\".\")\n",
        "\n",
        "neon_sel_002.to_csv(\"/content/drive/MyDrive/SENSECO/Outputs/Tables/CLBJ_002_csv.csv\")\n",
        "neon_sel_003.to_csv(\"/content/drive/MyDrive/SENSECO/Outputs/Tables/CLBJ_002_csv_Nuno.csv\",sep=\";\",decimal=\".\")\n",
        "\n",
        "neon_sel_003.to_csv(\"/content/drive/MyDrive/SENSECO/Outputs/Tables/CLBJ_003_csv.csv\")\n",
        "neon_sel_003.to_csv(\"/content/drive/MyDrive/SENSECO/Outputs/Tables/CLBJ_003_csv_Nuno.csv\",sep=\";\",decimal=\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWnCh2OFpuUR"
      },
      "source": [
        "#Step 2: RS data\n",
        "\n",
        "Here we will load the RS data and see how \"close\" our prediction was to the field data\n",
        "\n",
        "But first we must extract values to points:\n",
        "\n",
        "https://hatarilabs.com/ih-en/extract-point-value-from-a-raster-file-with-python-geopandas-and-rasterio-tutorial\n",
        "\n",
        "(using this tutorial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lInsijhUqT-w"
      },
      "source": [
        "## Loading Sample points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw7GiRFfqytL"
      },
      "source": [
        "#loading shapefile and make it a bit simpler\n",
        "shp_NEON = gpd.read_file(\"/content/drive/MyDrive/SENSECO/Shapefiles/NEON_DHP_Centroids_UTM14N.shp\")\n",
        "shp_NEON = shp_NEON[['geometry','plotID']]\n",
        "\n",
        "#loading a sample image with rasterio\n",
        "sample_img = rasterio.open(\"/content/drive/MyDrive/SENSECO/Outputs/Rasters/S2A_MSIL2A_20190321_0030_LAI.tif\")\n",
        "\n",
        "#show point and raster on a matplotlib plot\n",
        "fig, ax = plt.subplots(figsize=(12,12))\n",
        "shp_NEON.plot(ax=ax, color='orangered')\n",
        "show(sample_img, ax=ax)\n",
        "\n",
        "#example of how to get the poitns\n",
        "for point in shp_NEON['geometry']:\n",
        "    x = point.xy[0][0]\n",
        "    y = point.xy[1][0]\n",
        "    row, col = sample_img.index(x,y)\n",
        "    print(\"Point correspond to row, col: %d, %d\"%(row,col))\n",
        "    print(\"Raster value on point %.2f \\n\"%sample_img.read(1)[row,col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCjzny8oylQX"
      },
      "source": [
        "## Extracting raster values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PBQkbDfyoQ1"
      },
      "source": [
        "#create an object with the paths to files\n",
        "path2files = glob.glob(\"/content/drive/MyDrive/SENSECO/Outputs/Rasters/*LAI.tif\")\n",
        "\n",
        "#an object to store an output path\n",
        "outpath = \"/content/drive/MyDrive/SENSECO/Outputs/Tables/\"\n",
        "\n",
        "#an object to store the output data\n",
        "out_df =  pd.DataFrame(columns=[\"plotID\",\"Model\",\"ImageName\",\"YYYYMMDD\",\"LAI\"])\n",
        "\n",
        "for i in range(len(path2files)):\n",
        "\n",
        "  #print(i)\n",
        "  temp_path = path2files[i]\n",
        "\n",
        "  #fetches model used\n",
        "  temp_mdl  = temp_path[67:71]\n",
        "\n",
        "  #adapt this this if you change your path to the files, it should return: e.g. S2B_MSIL2A_20190105\n",
        "  temp_name = temp_path[47:]\n",
        "  \n",
        "  #fetches date in yyyymmdd format\n",
        "  temp_date = temp_path[58:66]\n",
        "\n",
        "  #print(\"Processing: \" + temp_name + \" \" +  str(i) +\"/\" + str(len(path2files)-1))\n",
        "\n",
        "  #loads the raster\n",
        "  tmp_img = rasterio.open(temp_path)\n",
        "\n",
        "  #adds the data\n",
        "  for j in range(shp_NEON.shape[0]):\n",
        "\n",
        "    #fetching the ifno\n",
        "    point = shp_NEON['geometry'][j]\n",
        "    x = point.xy[0][0]\n",
        "    y = point.xy[1][0]\n",
        "    row, col = tmp_img.index(x,y)\n",
        "    out_val = tmp_img.read(1)[row,col]\n",
        "\n",
        "    #adding to out_df\n",
        "    out_df = out_df.append({\"plotID\":shp_NEON['plotID'][j],\n",
        "                            \"Model\":temp_mdl,\n",
        "                            \"ImageName\":temp_name,\n",
        "                            \"YYYYMMDD\":temp_date,\n",
        "                            \"LAI\":out_val},\n",
        "                           ignore_index=True)\n",
        "\n",
        "out_df.to_csv(outpath +  \"LAI_RS_csv.csv\")\n",
        "out_df.to_csv(outpath +  \"LAI_RS_csvN.csv\",decimal=\".\",sep=\";\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ-65O4I_usT"
      },
      "source": [
        "## Setting up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-FY_Mej__hY"
      },
      "source": [
        "rs_data = out_df\n",
        "\n",
        "#creating a date time\n",
        "rs_data[\"ymd\"] = rs_data.YYYYMMDD.str[0:4] + \"-\" + rs_data.YYYYMMDD.str[4:6]  + \"-\" + rs_data.YYYYMMDD.str[6:] \n",
        "rs_data[\"datetime\"] = pd.to_datetime(rs_data.ymd)\n",
        "\n",
        "rs_data.index = rs_data['datetime']\n",
        "del rs_data['datetime']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOoDmplvC_qD"
      },
      "source": [
        "rs_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3g6KMuHANXi"
      },
      "source": [
        "#optinal plotting\n",
        "#rs_data.groupby([\"plotID\",\"Model\"]).plot(y=\"LAI\",style='.',figsize=(15,5), title = \"RS data\")\n",
        "rs_data.groupby([\"plotID\"])[\"LAI\"].plot(y=\"LAI\",style='.',figsize=(15,5))\n",
        "\n",
        "#again, im sure some of you will know how to improve thse plots xP "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SvIZHn3_qVW"
      },
      "source": [
        "# Step 3: Comparing both"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZf5nk2eLWFh"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdKmhv0xEQn6"
      },
      "source": [
        "#creating list of dates of RS data\n",
        "rs_date_list = rs_data.ymd.drop_duplicates().tolist()\n",
        "\n",
        "#selecting from the list of values\n",
        "pd_NEON001 = neon_sel_001[neon_sel_001.index.to_series().dt.date.astype(str).isin(rs_date_list)]\n",
        "pd_NEON002 = neon_sel_002[neon_sel_002.index.to_series().dt.date.astype(str).isin(rs_date_list)]\n",
        "pd_NEON003 = neon_sel_003[neon_sel_003.index.to_series().dt.date.astype(str).isin(rs_date_list)]  \n",
        "\n",
        "#now we must add these values back into the oriignal tables\n",
        "pd_RS001 = rs_data[rs_data['plotID']==\"CLBJ_001\"]\n",
        "pd_RS002 = rs_data[rs_data['plotID']==\"CLBJ_002\"]\n",
        "pd_RS003 = rs_data[rs_data['plotID']==\"CLBJ_003\"]\n",
        "\n",
        "#mergin dataframes\n",
        "pd_M001 = pd.merge(pd_NEON001,pd_RS001,how=\"left\",left_index=True, right_index=True)\n",
        "pd_M002 = pd.merge(pd_NEON002,pd_RS002,how=\"left\",left_index=True, right_index=True)\n",
        "pd_M003 = pd.merge(pd_NEON003,pd_RS003,how=\"left\",left_index=True, right_index=True)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3JxzHg0LSli"
      },
      "source": [
        "## Plotting results\n",
        "\n",
        "- Version 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p46Tr0Z-Nu_E"
      },
      "source": [
        "fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15, 5))\n",
        "\n",
        "colors = {'rest':'tab:blue','0300':'tab:orange', '0030':'tab:green'}\n",
        "\n",
        "ref_data = 'Final_LAIe'\n",
        "\n",
        "grouped = pd_M001.groupby([\"Model\"])\n",
        "for key, group in grouped:\n",
        "  group.plot(ax=ax1, kind='scatter', x=ref_data, y='LAI', label=key, color=colors[key],xlim=(0.5,2),ylim=(0.5,4),title=\"CBLJ_001\")\n",
        "#plt.show()\n",
        "\n",
        "grouped = pd_M002.groupby([\"Model\"])\n",
        "for key, group in grouped:\n",
        "  group.plot(ax=ax2, kind='scatter', x=ref_data, y='LAI', label=key, color=colors[key],xlim=(0.5,2),ylim=(0.5,4),title=\"CBLJ_002\")\n",
        "#plt.show()\n",
        "\n",
        "grouped = pd_M003.groupby([\"Model\"])\n",
        "for key, group in grouped:\n",
        "  group.plot(ax=ax3, kind='scatter', x=ref_data, y='LAI', label=key, color=colors[key],xlim=(0.5,2),ylim=(0.5,4),title=\"CBLJ_003\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZWBO1SBfl0w"
      },
      "source": [
        "- Version 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLSNIm0OflPu"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#combines all data\n",
        "comb_data = pd.concat([pd_M001,pd_M002,pd_M003])\n",
        "\n",
        "#create the FaceGrid\n",
        "g = sns.FacetGrid(comb_data, \n",
        "                  col=\"plotID\", \n",
        "                  row='Model',\n",
        "                  sharey=False,\n",
        "                  hue='Model')\n",
        "                  #hue='Model', \n",
        "                  #col_wrap=3, # here it means 2 columns depending on the position you want\n",
        "                  #legend_out=True) \n",
        "\n",
        "g.map(sns.scatterplot, 'Final_LAIe', 'LAI').add_legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JWAKJX3SWGo"
      },
      "source": [
        "## Measuring error\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iNiroiBTWrO"
      },
      "source": [
        "#combining all\n",
        "pd_MALL = pd.concat([pd_M001,pd_M002,pd_M003]) \n",
        "\n",
        "mdl_list    = pd_MALL.Model.drop_duplicates().tolist()\n",
        "plotID_list = pd_MALL.plotID.drop_duplicates().tolist()  \n",
        "\n",
        "ref_lai = \"Final_LAIe\"\n",
        "\n",
        "\n",
        "for i in range(len(mdl_list)):\n",
        "\n",
        "  \n",
        "  for j in range(len(plotID_list)):\n",
        "\n",
        "    pd_temp = pd_MALL[(pd_MALL['Model'] == mdl_list[i]) & (pd_MALL['plotID'] ==plotID_list[j])]\n",
        "\n",
        "    tmp_r2 = mean_absolute_error(y_true=pd_temp[ref_lai],y_pred=pd_temp[\"LAI\"])\n",
        "    #tmp_MAE = mean_absolute_error(y_true=pd_temp[ref_lai],y_pred=pd_temp[\"LAI\"])\n",
        "\n",
        "    print(\"Model: \" + mdl_list[i] + \" plotID: \" + plotID_list[j] + \" Mean absolute error:  \" + str(round(tmp_r2,4)) )\n",
        "    #print(\"Model: \" + mdl_list[i] + \" plotID: \" + plotID_list[j] + \" MAE: \" + str(round(tmp_MAE,4)) )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}