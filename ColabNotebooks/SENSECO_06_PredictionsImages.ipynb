{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENSECO_06_PredictionsImages.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMsa435RJ2QLiSx9JUZftmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nunocesarsa/SENSECO_School_2021/blob/main/ColabNotebooks/SENSECO_06_PredictionsImages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2n9Bufzy7hV"
      },
      "source": [
        "#Setting up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHheixMfzBu9"
      },
      "source": [
        "## AutoSklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN8UiRKTys6Y"
      },
      "source": [
        "#source: https://colab.research.google.com/github/vopani/fortyone/blob/main/notebooks/automl/tabular/Auto-Sklearn.ipynb#scrollTo=yFSo4OV0FOZN\n",
        "\n",
        "!python3 -m pip install --upgrade pip\n",
        "!pip3 install scikit-learn==0.24.1\n",
        "!pip3 install pandas\n",
        "\n",
        "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip3 install\n",
        "!pip3 install auto-sklearn\n",
        "\n",
        "!pip install PipelineProfiler\n",
        "#NOTICE: you might be required to restart runtime before proceeding - Ctrl + M\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ki7WlG-iFq3"
      },
      "source": [
        "## Restart runtime!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZljmyuEzy7Jo"
      },
      "source": [
        "#quick test - if needed\n",
        "from autosklearn.classification import AutoSklearnClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer(as_frame=True)['data']\n",
        "target = load_breast_cancer(as_frame=True)['target']\n",
        "\n",
        "sklearn_aml = AutoSklearnClassifier(time_left_for_this_task=30)\n",
        "sklearn_aml.fit(X=data, y=target)\n",
        "\n",
        "import PipelineProfiler\n",
        "prof_data = PipelineProfiler.import_autosklearn(sklearn_aml)\n",
        "PipelineProfiler.plot_pipeline_matrix(prof_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34zdR3Fgzi6G"
      },
      "source": [
        "## GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxRGK07tzpYV",
        "outputId": "73e9a93f-ba44-4098-d956-acf2fc04fe03"
      },
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOrUTDL3zvF_"
      },
      "source": [
        "## Installing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvLQrGPWzwlU"
      },
      "source": [
        "#Installing PROSAIL\n",
        "!pip install prosail\n",
        "\n",
        "#latin hypercube stuff\n",
        "!pip install lhsmdu\n",
        "\n",
        "#this package as a number of functions to deal with hyperspectral data\n",
        "!pip install pysptools\n",
        "\n",
        "#geographic stuff related packages\n",
        "!pip install rasterio\n",
        "#!pip install geopandas\n",
        "!pip install earthpy\n",
        "#!pip install rasterstats\n",
        "\n",
        "!pip install pyrsgis\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkRLMz9w0D1-"
      },
      "source": [
        "## Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTfGhwx90Ka1"
      },
      "source": [
        "#General purpose: \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "#for saving model data\n",
        "import pickle #for storing data\n",
        "import joblib\n",
        "\n",
        "#the beutiful R like data frame\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "#PROSPECT+SAIL Radiative transfer mode package\n",
        "import prosail\n",
        "\n",
        "#Sampling design package\n",
        "import lhsmdu\n",
        "\n",
        "#a few more stuff for random\n",
        "import random as rdm\n",
        "import math\n",
        "\n",
        "#package to for operations on spectral data\n",
        "import pysptools as sptool \n",
        "from pysptools import distance\n",
        "\n",
        "## AutoML\n",
        "import autosklearn\n",
        "from autosklearn.regression import AutoSklearnRegressor\n",
        "import PipelineProfiler\n",
        "\n",
        "\n",
        "## Scikit learn metrics stuff\n",
        "import sklearn.metrics\n",
        "\n",
        "## Geoinformation stuff\n",
        "from pyrsgis.convert import changeDimension\n",
        "from pyrsgis import raster\n",
        "\n",
        "#raster plotting\n",
        "import earthpy.plot as ep\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kS-_uiI0ziX"
      },
      "source": [
        "#Step 1: Load the saved models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iSc0oZ305h9"
      },
      "source": [
        "AutoRTM_0030 =joblib.load('/content/drive/MyDrive/SENSECO/Models/AutoRTM_0030.pkl')\n",
        "AutoRTM_0300 =joblib.load('/content/drive/MyDrive/SENSECO/Models/AutoRTM_0300.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQYC6u1P1OIu"
      },
      "source": [
        "## \"Special\" model:\n",
        "\n",
        "If we try: \n",
        "\n",
        "```\n",
        "AutoRTM_rest =joblib.load('/content/drive/MyDrive/SENSECO/Models/AutoRTM_Restricted.pkl')\n",
        "```\n",
        "It causes the following error:\n",
        "\n",
        "```\n",
        "AttributeError: module '__main__' has no attribute 'GaussianProcess2'\n",
        "```\n",
        "\n",
        "This is because the model does not exist in the vanilla AutoSklearn. We have to re-add it first\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnMjzCdF1JlV"
      },
      "source": [
        "from ConfigSpace.configuration_space import ConfigurationSpace\n",
        "from ConfigSpace.hyperparameters import UniformFloatHyperparameter\n",
        "\n",
        "from autosklearn.pipeline.components.base import AutoSklearnRegressionAlgorithm\n",
        "from autosklearn.pipeline.constants import DENSE, UNSIGNED_DATA, PREDICTIONS\n",
        "\n",
        "#creating the class\n",
        "class GaussianProcess2(AutoSklearnRegressionAlgorithm):\n",
        "    def __init__(self, alpha, thetaL, thetaU, random_state=None):\n",
        "        self.alpha = alpha\n",
        "        self.thetaL = thetaL\n",
        "        self.thetaU = thetaU\n",
        "        # We ignore it\n",
        "        self.random_state = random_state\n",
        "        self.estimator = None\n",
        "        self.scaler = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        import sklearn.gaussian_process\n",
        "\n",
        "        self.alpha = float(self.alpha)\n",
        "        self.thetaL = float(self.thetaL)\n",
        "        self.thetaU = float(self.thetaU)\n",
        "\n",
        "        n_features = X.shape[1] \n",
        "        kernel = sklearn.gaussian_process.kernels.RBF( #here we could change the kernel parameters - notice also that deeper changes are needed to allow for kernel search\n",
        "            length_scale=[1.0]*n_features,\n",
        "            length_scale_bounds=[(self.thetaL, self.thetaU)]*n_features)\n",
        "\n",
        "        # Instanciate a Gaussian Process model\n",
        "        self.estimator = sklearn.gaussian_process.GaussianProcessRegressor(\n",
        "            kernel=kernel,\n",
        "            n_restarts_optimizer=10,\n",
        "            optimizer='fmin_l_bfgs_b',\n",
        "            alpha=self.alpha,\n",
        "            copy_X_train=True,\n",
        "            random_state=self.random_state,\n",
        "            normalize_y=True)\n",
        "\n",
        "        self.estimator.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.estimator is None:\n",
        "            raise NotImplementedError\n",
        "        return self.estimator.predict(X)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_properties(dataset_properties=None):\n",
        "        return {'shortname': 'GP',\n",
        "                'name': 'Gaussian Process',\n",
        "                'handles_regression': True,\n",
        "                'handles_classification': False,\n",
        "                'handles_multiclass': False,\n",
        "                'handles_multilabel': False,\n",
        "                'handles_multioutput': True,\n",
        "                'is_deterministic': True,\n",
        "                'input': (DENSE, UNSIGNED_DATA),\n",
        "                'output': (PREDICTIONS,)}\n",
        "\n",
        "    @staticmethod\n",
        "    def get_hyperparameter_search_space(dataset_properties=None):\n",
        "        alpha = UniformFloatHyperparameter(\n",
        "            name=\"alpha\", lower=0.05, upper=1.0, default_value=0.05, log=True) #here we want to force a mininum noise value\n",
        "        thetaL = UniformFloatHyperparameter(\n",
        "            name=\"thetaL\", lower=1e-10, upper=1e-3, default_value=1e-6, log=True)\n",
        "        thetaU = UniformFloatHyperparameter(\n",
        "            name=\"thetaU\", lower=1.0, upper=100000, default_value=100000.0, log=True)\n",
        "\n",
        "        cs = ConfigurationSpace()\n",
        "        cs.add_hyperparameters([alpha, thetaL, thetaU])\n",
        "        return cs\n",
        "\n",
        "#adding it to the pipeline\n",
        "autosklearn.pipeline.components.regression.add_regressor(GaussianProcess2)\n",
        "\n",
        "#loading the model \n",
        "AutoRTM_rest =joblib.load('/content/drive/MyDrive/SENSECO/Models/AutoRTM_Restricted.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsP-4OUF1TP1"
      },
      "source": [
        "### Confirming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIhYIdzrUflR"
      },
      "source": [
        "loaded_mdl_pipeline = PipelineProfiler.import_autosklearn(AutoRTM_rest)\n",
        "PipelineProfiler.plot_pipeline_matrix(loaded_mdl_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfgEeHnkVHmg"
      },
      "source": [
        "#Step 2: Loading raster data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPvVM2JOcGTN"
      },
      "source": [
        "## Details\n",
        "\n",
        "The band order was set already when downloading from GEE:\n",
        "\n",
        "```\n",
        "#this command creates an object which is already filtered to the aoi\n",
        "s2_collection = (ee.ImageCollection(\"COPERNICUS/S2_SR\") #selects the L8 Surface reflectance product in GEE\n",
        "                 .select(['B2','B3','B4',#'B8A'\n",
        "                          'B5','B6','B7',\n",
        "                          'B8A','B11','B12'\n",
        "                          ]) #selects the bands of interest\n",
        "                 .filter(ee.Filter.date('2016-01-01','2020-03-01')) #filters on the time - you can play around with this to select different dates..\n",
        "                 .filterBounds(CLBJ_gee) #filters on the Aoi we have created above\n",
        "                 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',5))\n",
        "                 .filter(ee.Filter.inList('MGRS_TILE', tilelist)))\n",
        "```\n",
        "\n",
        "Thus:\n",
        "B2, B3, ... B8A, B11, B12\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZp1KziPYg_A"
      },
      "source": [
        "## Example in one image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o8UzpRLWt-Y"
      },
      "source": [
        "ds1, bands = raster.read('/content/drive/MyDrive/SENSECO_S2Data/S2A_MSIL2A_20190321_T14SPC.tif')\n",
        "\n",
        "print(ds1)\n",
        "print(bands.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaqSjnX-at74"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Plot red, green, and blue bands, respectively\n",
        "ep.plot_rgb(bands, rgb=(2,1,0), ax=ax, title=\"Sentinel 2 RGB\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKKWIH5zc36F"
      },
      "source": [
        "### Applying AutoSklearn\n",
        "\n",
        "Autosklearn expects data inputed as a table, so we must transform the raster into a table.\n",
        "\n",
        "In this table, the rows represent each pixel while the columns represent each feature (band). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhrGSkw3jeXl"
      },
      "source": [
        "### Spectral data prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qseMRuomcS9t"
      },
      "source": [
        "bandByPixel = changeDimension(bands)/10000. #we have to devide all values by 10000 - https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR\n",
        "bandByPixel_t = np.transpose(bandByPixel)\n",
        "\n",
        "print(bandByPixel.shape)\n",
        "print(bandByPixel_t.shape)\n",
        "\n",
        "pd_bandByPixel = pd.DataFrame(data=bandByPixel,columns=['B02','B03','B04',\n",
        "                                                        'B05','B06','B07',\n",
        "                                                        'B8A','B11','B12'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_TrspEXjYZj"
      },
      "source": [
        "### Geometry data prep\n",
        "\n",
        "- this could of course be much more advanced to consdie each pixel geometry and not generalize a mean value\n",
        "\n",
        "- this means are from CSV created with the different acquisition geometries on the GEE step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2scOiGZjckz"
      },
      "source": [
        "#creating repeating list\n",
        "np_sun_zen = np.repeat(37.534,6715)\n",
        "np_sen_zen = np.repeat(4.118,6715)\n",
        "np_rel_azi = np.repeat(101.531,6715)\n",
        "\n",
        "#combinning\n",
        "geom_stack = np.stack((np_sun_zen,np_sen_zen,np_rel_azi),axis=1)\n",
        "\n",
        "#creating dataframe\n",
        "pd_geomByPixel = pd.DataFrame(data=geom_stack,columns=[\"sol_zen\",\"inc_zen\",\"raa\"])\n",
        "#pd_geomByPixel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB3F6bpWnaCy"
      },
      "source": [
        "Finally we can combine both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrmRXyLNncN7"
      },
      "source": [
        "pd_Combined = pd.concat([pd_geomByPixel, pd_bandByPixel], axis=1)\n",
        "pd_Combined "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UWfbKf8i2TT"
      },
      "source": [
        "### Predictions\n",
        "\n",
        "- if your image is too big.. this part will have problems and has to be adapted to predict section by section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGdOAqItjHrb"
      },
      "source": [
        "AutoRTM_0030_pred = AutoRTM_0030.predict(pd_Combined )\n",
        "AutoRTM_0300_pred = AutoRTM_0300.predict(pd_Combined )\n",
        "AutoRTM_rest_pred = AutoRTM_rest.predict(pd_Combined )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivUv9hqRoBkd"
      },
      "source": [
        "### Reconstructing the raster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXTti83Aocmq"
      },
      "source": [
        "print(AutoRTM_0030_pred.shape)\n",
        "AutoRTM_0030_pred "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLakefhCovyy"
      },
      "source": [
        "Each column is one of the outputs. Our model was trainged to predict Cab and LAI in this order and so the first column is Cab and the secon LAI.\n",
        "\n",
        "We must now reconstruct one by one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfEtRyW8oe6x"
      },
      "source": [
        "#first a single array\n",
        "AutoRTM_0030_pred_cab = AutoRTM_0030_pred[:,0]\n",
        "AutoRTM_0030_pred_lai = AutoRTM_0030_pred[:,1]\n",
        "\n",
        "AutoRTM_0300_pred_cab = AutoRTM_0300_pred[:,0]\n",
        "AutoRTM_0300_pred_lai = AutoRTM_0300_pred[:,1]\n",
        "\n",
        "AutoRTM_rest_pred_cab = AutoRTM_rest_pred[:,0]\n",
        "AutoRTM_rest_pred_lai = AutoRTM_rest_pred[:,1]\n",
        "\n",
        "#and then we can start the reshape back again using the raster information:\n",
        "rst_cab_0030 = np.reshape(AutoRTM_0030_pred_cab,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "rst_lai_0030 = np.reshape(AutoRTM_0030_pred_lai,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "\n",
        "rst_cab_0300 = np.reshape(AutoRTM_0300_pred_cab,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "rst_lai_0300 = np.reshape(AutoRTM_0300_pred_lai,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "\n",
        "rst_cab_rest = np.reshape(AutoRTM_rest_pred_cab,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "rst_lai_rest = np.reshape(AutoRTM_rest_pred_lai,(ds1.RasterYSize,ds1.RasterXSize))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ_uSX9zpl-9"
      },
      "source": [
        "### Visualizing\n",
        "\n",
        "- python is not the best for this (imo) but we can just save it as araster and explore in a GIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPbveNliqA5U"
      },
      "source": [
        "#setting max\n",
        "cab_min = 5\n",
        "cab_max = 90\n",
        "lai_min = 0.5\n",
        "lai_max = 8\n",
        "#color map settings\n",
        "cab_cmap = 'RdYlGn'\n",
        "lai_cmap = 'Greens'\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(3, 2,figsize=(15,15))\n",
        "\n",
        "axs[0, 0].imshow(rst_cab_0030,vmin=cab_min, vmax=cab_max,cmap=cab_cmap)\n",
        "axs[0, 0].set_title('Cab 30s')\n",
        "axs[0, 1].imshow(rst_lai_0030,vmin=lai_min, vmax=lai_max,cmap=lai_cmap)\n",
        "axs[0, 1].set_title('LAI 30s')\n",
        "fig.subplots_adjust(right=0.85)\n",
        "\n",
        "axs[1, 0].imshow(rst_cab_0300,vmin=cab_min, vmax=cab_max,cmap=cab_cmap)\n",
        "axs[1, 0].set_title('Cab 300s')\n",
        "axs[1, 1].imshow(rst_lai_0300,vmin=lai_min, vmax=lai_max,cmap=lai_cmap)\n",
        "axs[1, 1].set_title('LAI 300s')\n",
        "fig.subplots_adjust(right=0.85)\n",
        "\n",
        "axs[2, 0].imshow(rst_cab_rest,vmin=cab_min, vmax=cab_max,cmap=cab_cmap)\n",
        "axs[2, 0].set_title('Cab GP special')\n",
        "axs[2, 1].imshow(rst_lai_rest,vmin=lai_min, vmax=lai_max,cmap=lai_cmap)\n",
        "axs[2, 1].set_title('LAI GP special')\n",
        "fig.subplots_adjust(right=0.85)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVb_Sv5spFhy"
      },
      "source": [
        "### Saving as GeoTiff\n",
        "\n",
        "- feel free to do a quick exploration "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssrkPOAAxJ1p"
      },
      "source": [
        "raster.export(rst_cab_0030, ds1, '/content/drive/MyDrive/SENSECO/Cab_0030_test.tif',dtype='float')\n",
        "raster.export(rst_lai_0030, ds1, '/content/drive/MyDrive/SENSECO/LAI_0030_test.tif',dtype='float')\n",
        "\n",
        "raster.export(rst_cab_0300, ds1, '/content/drive/MyDrive/SENSECO/Cab_0300_test.tif',dtype='float')\n",
        "raster.export(rst_lai_0300, ds1, '/content/drive/MyDrive/SENSECO/LAI_0300_test.tif',dtype='float')\n",
        "\n",
        "raster.export(rst_cab_rest, ds1, '/content/drive/MyDrive/SENSECO/Cab_rest_test.tif',dtype='float')\n",
        "raster.export(rst_lai_rest, ds1, '/content/drive/MyDrive/SENSECO/LAI_rest_test.tif',dtype='float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD61IvNQ0SK5"
      },
      "source": [
        "#Step 3: Loop\n",
        "\n",
        "- Putting the above steps into a loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrLIBaIs9cKW"
      },
      "source": [
        "\n",
        "#loading the csv file with the angle properties\n",
        "df_geoms = pd.read_csv(\"/content/drive/MyDrive/SENSECO_S2Data/AngleInformation.csv\")\n",
        "\n",
        "#adding a column with part of the name only\n",
        "df_geoms[\"NameOnly\"]=df_geoms.Imagename.str[:19]\n",
        "\n",
        "#create an object with the paths to files\n",
        "path2files = glob(\"/content/drive/MyDrive/SENSECO_S2Data/*.tif\")\n",
        "\n",
        "#an object to store an output path\n",
        "outpath = \"/content/drive/MyDrive/SENSECO/Outputs/Rasters/\"\n",
        "\n",
        "for i in range(len(path2files)):\n",
        "\n",
        "  #print(i)\n",
        "  temp_path = path2files[i]\n",
        "\n",
        "  #adapt this this if you change your path to the files, it should return: e.g. S2B_MSIL2A_20190105\n",
        "  temp_name = temp_path[38:57]\n",
        "\n",
        "  print(\"Processing: \" + temp_name + \" \" +  str(i) +\"/\" + str(len(path2files)))\n",
        "\n",
        "  #selecting the row of interest in the dataframe\n",
        "  temp_df_sel = df_geoms[df_geoms[\"NameOnly\"]==temp_name]\n",
        "\n",
        "  #opening the raster\n",
        "  ds1, bands = raster.read(temp_path)\n",
        "\n",
        "  #Preparing spectral data:\n",
        "  bandByPixel = changeDimension(bands)/10000. #we have to devide all values by 10000 - https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR\n",
        "  bandByPixel_t = np.transpose(bandByPixel)\n",
        "  pd_bandByPixel = pd.DataFrame(data=bandByPixel,columns=['B02','B03','B04',\n",
        "                                                          'B05','B06','B07',\n",
        "                                                          'B8A','B11','B12'])\n",
        "\n",
        "  #Preparing the sensor data\n",
        "  np_sun_zen = np.repeat(temp_df_sel['Sol_Zenith'].iloc[0],ds1.RasterXSize*ds1.RasterYSize)\n",
        "  np_sen_zen = np.repeat(temp_df_sel['Sen_Zenith'].iloc[0],ds1.RasterXSize*ds1.RasterYSize)\n",
        "  np_rel_azi = np.repeat(temp_df_sel['Sen_Azimuth'].iloc[0]-temp_df_sel['Sol_Azimuth'].iloc[0],ds1.RasterXSize*ds1.RasterYSize)\n",
        "\n",
        "  geom_stack = np.stack((np_sun_zen,np_sen_zen,np_rel_azi),axis=1)\n",
        "  pd_geomByPixel = pd.DataFrame(data=geom_stack,columns=[\"sol_zen\",\"inc_zen\",\"raa\"])\n",
        "\n",
        "  #putting it togeteher\n",
        "  pd_Combined = pd.concat([pd_geomByPixel, pd_bandByPixel], axis=1)\n",
        " \n",
        "  #Finally predictions:\n",
        "  AutoRTM_0030_pred = AutoRTM_0030.predict(pd_Combined )\n",
        "  AutoRTM_0300_pred = AutoRTM_0300.predict(pd_Combined )\n",
        "  AutoRTM_rest_pred = AutoRTM_rest.predict(pd_Combined )  \n",
        "\n",
        "  #Reconstructing the rasters and saving\n",
        "  AutoRTM_0030_pred_cab = AutoRTM_0030_pred[:,0]\n",
        "  AutoRTM_0030_pred_lai = AutoRTM_0030_pred[:,1]\n",
        "\n",
        "  AutoRTM_0300_pred_cab = AutoRTM_0300_pred[:,0]\n",
        "  AutoRTM_0300_pred_lai = AutoRTM_0300_pred[:,1]\n",
        "\n",
        "  AutoRTM_rest_pred_cab = AutoRTM_rest_pred[:,0]\n",
        "  AutoRTM_rest_pred_lai = AutoRTM_rest_pred[:,1]\n",
        "\n",
        "  #and then we can start the reshape back again using the raster information:\n",
        "  rst_cab_0030 = np.reshape(AutoRTM_0030_pred_cab,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "  rst_lai_0030 = np.reshape(AutoRTM_0030_pred_lai,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "\n",
        "  rst_cab_0300 = np.reshape(AutoRTM_0300_pred_cab,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "  rst_lai_0300 = np.reshape(AutoRTM_0300_pred_lai,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "\n",
        "  rst_cab_rest = np.reshape(AutoRTM_rest_pred_cab,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "  rst_lai_rest = np.reshape(AutoRTM_rest_pred_lai,(ds1.RasterYSize,ds1.RasterXSize))\n",
        "\n",
        "  #storing the rasters\n",
        "  raster.export(rst_cab_0030, ds1, outpath + temp_name + \"_0030_Cab.tif\",dtype='float')\n",
        "  raster.export(rst_lai_0030, ds1, outpath + temp_name + \"_0030_LAI.tif\",dtype='float')\n",
        "\n",
        "  raster.export(rst_cab_0300, ds1, outpath + temp_name + \"_0300_Cab.tif\",dtype='float')\n",
        "  raster.export(rst_lai_0300, ds1, outpath + temp_name + \"_0300_LAI.tif\",dtype='float')\n",
        "\n",
        "  raster.export(rst_cab_rest, ds1, outpath + temp_name + \"_rest_Cab.tif\",dtype='float')\n",
        "  raster.export(rst_lai_rest, ds1, outpath + temp_name + \"_rest_LAI.tif\",dtype='float')\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}